{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95325614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,7)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "#make sure that opencv optimisation is enabled\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "    \n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4822fb1",
   "metadata": {},
   "source": [
    "1. convert the code chunk food under section Divide an image into smaller patches using cropping into a function with the following signature:\n",
    "crop_grid(img, num_horizonta_grid, num_vertical_grid, line_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc3e52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 1 - FUNCTION\n",
    "#img is the source image \n",
    "#num_horizontal_grid and num_vertical_grid are the number of patches along x and y axes. \n",
    "#line_color is the color of the grid line \n",
    "#the output of the function should be image with grids\n",
    "def crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color):\n",
    "    \n",
    "    img_copy = img.copy()\n",
    "    #this will return the height and width of the picture\n",
    "    height, width = img.shape[:2]\n",
    "        \n",
    "    #M and N are basically number of pixels per patch\n",
    "    M, N = int(height/num_horizontal_grid), int(width/num_vertical_grid)\n",
    "    \n",
    "    x1, y1 = 0, 0\n",
    "    \n",
    "    for y in range(0, height, M):\n",
    "        for x in range(0, width, N):\n",
    "            \n",
    "            y1 = y + M    \n",
    "            x1 = x + N\n",
    "\n",
    "            if x1 >= width and y1 >= height:\n",
    "                x1 = width - 1\n",
    "                y1 = height - 1\n",
    "                tile = img[y:height, x:width]\n",
    "                #255 (0,255,0) means that green line\n",
    "                #the 1 at the end is width of the line\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "                #cv.imshow('tile', tile)\n",
    "            # When patch lower right y-coordinate exceeds patch height\n",
    "            elif y1 >= height:\n",
    "                y1 = height - 1\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "            # When patch lower right x-coordinate exceeds patch width\n",
    "            elif x1 >= width:\n",
    "                x1 = width - 1\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "            else:\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b26f2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 1 - TEST THE FUNCTION\n",
    "img = cv.imread(\"dog.jfif\")\n",
    "\n",
    "#line color is correspond to (B,G,R)\n",
    "img2 = crop_grid(img, 2, 2, (255, 255, 255))\n",
    "\n",
    "cv.imshow(\"inverse mask\",img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d850ab3",
   "metadata": {},
   "source": [
    "2. Display image sequences of smooth transition of two images with different value of α. Refer to code in section \"image blending\". use \"lena.jfif\" and \"coins.jfif\" as the base images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7feba382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 2\n",
    "img1 = cv.imread(\"lena.jfif\")\n",
    "img2 = cv.imread(\"coins.jfif\")\n",
    "\n",
    "#Resize img2\n",
    "new_shape = img1.shape[:2]\n",
    "img2 = cv.resize(img2, new_shape)\n",
    "\n",
    "dst1 = cv.addWeighted(img1,0.75,img2 ,0.25,0)\n",
    "dst2 = cv.addWeighted(img1,0.5,img2 ,0.25,0)\n",
    "dst3 = cv.addWeighted(img1,0.25,img2 ,0.25,0)\n",
    "\n",
    "cv.imshow(\"lena_base\",img1)\n",
    "cv.imshow(\"coin_base\",img2)\n",
    "cv.imshow(\"0.75α\", dst1)\n",
    "cv.imshow(\"0.50α\", dst2)\n",
    "cv.imshow(\"0.25α\", dst3)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b1f3d",
   "metadata": {},
   "source": [
    "3. Rotate image by 45 degrees without croppping the sides of the image (Hint: There are 2 strategies to tackle these problems). use \"lena.jfif\" as the input image.\n",
    "- use external libraries `imutils`.\n",
    "-modify the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d5cf2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3\n",
    "#Method 1\n",
    "import imutils as im\n",
    "\n",
    "img = cv.imread(\"lena.jfif\")\n",
    "\n",
    "#first parameter is the source image\n",
    "#second parameter is the angle to rotate\n",
    "rotate = im.rotate_bound(img, 45)\n",
    "\n",
    "cv.imshow(\"result\",rotate)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cde6e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3\n",
    "#Method 2\n",
    "import math\n",
    "\n",
    "def rotate_about_center(src, angle, scale):\n",
    "    \n",
    "    width = src.shape[1] #take the width value of the source image\n",
    "    height = src.shape[0] #take the height value of the source image\n",
    "    \n",
    "    radian = np.deg2rad(angle)  # covert the angle into radian\n",
    "    \n",
    "    # calculate the width and height of the new image\n",
    "    newWidth = (abs(np.sin(radian)*height) + abs(np.cos(radian)*width))*scale\n",
    "    newHeight = (abs(np.cos(radian)*height) + abs(np.sin(radian)*width))*scale\n",
    "    \n",
    "    #use getRotationMatrix2D function to get the rotation matrix\n",
    "    rotation_matrix = cv.getRotationMatrix2D((newWidth*0.5, newHeight*0.5), angle, scale)\n",
    "\n",
    "    \n",
    "    # calculate to get the new rotation and center\n",
    "    rotation_move = np.dot(rotation_matrix, np.array([(newWidth-width)*0.5, (newHeight-height)*0.5,0]))\n",
    "   \n",
    "    # the move only affects the translation, so update the translation\n",
    "    # part of the transform\n",
    "    rotation_matrix[0,2] += rotation_move[0]\n",
    "    rotation_matrix[1,2] += rotation_move[1]\n",
    "    \n",
    "    return cv.warpAffine(src, rotation_matrix, (int(math.ceil(newWidth)), int(math.ceil(newHeight))), flags=cv.INTER_LANCZOS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c558458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 3\n",
    "#METHOD 2\n",
    "\n",
    "img = cv.imread(\"lena.jfif\")\n",
    "\n",
    "#the first parameter is the source of the image\n",
    "#the second parameter is the degree of the rotation\n",
    "#the third parameter is the scale of the image\n",
    "rotated_image = rotate_about_center(img,45,1)\n",
    "\n",
    "cv.imshow(\"result\",rotated_image)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09262dd7",
   "metadata": {},
   "source": [
    "4. Use the images with titles: _\"flower.jfif\"_ and *\"native-bee.png\"*. I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are `cv.bitwise_and()`, `cv.bitwise_or()` and `cv.bitwise_not()`. You need to use `cv.threshold` function to segment the flower. Please refer to [online documentation](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga60b4d04b251ba5eb1392c34425497e14) for more info. The result should resemble the following:  \n",
    "![bee and flowers](image_embed/activity3.PNG \"bee_flower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d240d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION 4\n",
    "#load two image\n",
    "lebah = cv.imread(\"native-bee.png\")\n",
    "bunga = cv.imread(\"flower.jfif\")\n",
    "\n",
    "#get the roi of the flower\n",
    "#create roi\n",
    "roi = lebah[0:bunga.shape[0], 0:bunga.shape[1]]\n",
    "\n",
    "# Create mask of flower and its inverse mask \n",
    "flower_gray = cv.cvtColor(bunga,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(flower_gray, 150, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "# Black out the mask of flower\n",
    "lebah_belakang = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "# Take region of flower\n",
    "bunga_depan = cv.bitwise_and(bunga,bunga,mask = mask)\n",
    "\n",
    "# Put flower in ROI and modify the bee image\n",
    "dst = cv.add(lebah_belakang,bunga_depan)\n",
    "lebah[0:bunga.shape[0], 0:bunga.shape[1]] = dst\n",
    "\n",
    "cv.imshow('output',lebah)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
